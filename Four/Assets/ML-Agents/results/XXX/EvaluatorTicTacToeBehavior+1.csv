Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
350000,1.4083683,17.182852807283762,-0.15556835,-0.19147684113967572,-0.19147684113967572,0.20890728,0.02144053,9.514087e-05,0.1317136,0.0015925088,1.0
400000,1.4068427,17.211216314639476,-0.16263084,-0.2152153129966825,-0.2152153129966825,0.20056736,0.02465918,7.360712e-05,0.12453568,0.0012343302,1.0
450000,1.4048669,17.309157509157508,-0.13572752,-0.17104166649800517,-0.17104166649800517,0.21046385,0.025099993,4.2859287e-05,0.11428641,0.0007228913,1.0
500000,1.4046644,17.239970824215902,-0.13584132,-0.1865312726169629,-0.1865312726169629,0.2092831,0.025848523,1.5180398e-05,0.105060115,0.00026249903,1.0
