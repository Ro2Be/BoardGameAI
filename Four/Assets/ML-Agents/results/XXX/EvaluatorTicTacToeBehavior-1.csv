Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
450000,1.4176805,22.34090909090909,0.1932638,0.20018866301599575,0.20018866301599575,0.1716094,0.026301965,3.802628e-05,0.112675406,0.0006425024,1.0
500000,1.4171396,22.452626641651033,0.20569515,0.22991322704519218,0.22991322704519218,0.164126,0.024534082,1.3405173e-05,0.10446837,0.00023297108,1.0
550000,1.4168943,22.41104868913858,0.2018241,0.18324672287218413,0.18324672287218413,None,None,None,None,None,0.0
600000,1.4168942,22.405430711610485,0.20278983,0.1987933052689786,0.1987933052689786,None,None,None,None,None,0.0
