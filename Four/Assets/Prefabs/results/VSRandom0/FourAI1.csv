Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
200000,1.0916672,6.5808,0.38315627,0.3851080864691753,0.3851080864691753,1.0
250000,0.9383371,6.420302760463046,0.42677137,0.4766993173048382,0.4766993173048382,1.0
300000,0.71105015,6.003501891021151,0.4853406,0.5154783583134893,0.5154783583134893,1.0
350000,0.58016896,5.908123791102515,0.500042,0.5487703785576126,0.5487703785576126,1.0
400000,0.46822256,5.740091668913454,0.5195303,0.5602588298732812,0.5602588298732812,1.0
450000,0.39491844,5.614153439153439,0.55551195,0.5912698412698413,0.5912698412698413,1.0
500000,0.36870685,5.624006359300477,0.56267166,0.5992315845257021,0.5992315845257021,1.0
